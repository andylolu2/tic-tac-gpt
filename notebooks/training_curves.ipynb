{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from lightning import fabric\n",
    "from transformer_lens import (\n",
    "    HookedTransformer,\n",
    "    HookedTransformerConfig,\n",
    "    FactoredMatrix,\n",
    "    ActivationCache,\n",
    ")\n",
    "from transformer_lens import utils\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import log_loss\n",
    "from einops import einsum, rearrange, unpack, repeat\n",
    "from matplotlib import cm, colors\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tic_tac_gpt.data import TicTacToeDataset, TicTacToeState, tensor_to_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "torch.set_default_device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = Path(\"out/model/exp24\")\n",
    "\n",
    "with open(checkpoint_dir / \"config.pkl\", \"rb\") as f:\n",
    "    config: HookedTransformerConfig = pickle.load(f)\n",
    "F = fabric.Fabric(precision=\"16-mixed\")\n",
    "\n",
    "\n",
    "def load_checkpoint(step: int):\n",
    "    state_dict = F.load(checkpoint_dir / f\"model_{step}.pt\")\n",
    "    model = HookedTransformer(config)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_norm(model):\n",
    "    return torch.cat([p.view(-1) for p in model.parameters()]).norm().item()\n",
    "\n",
    "\n",
    "norms = [weight_norm(load_checkpoint(step)) for step in range(1000, 40000, 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=range(1000, 40000, 1000), y=norms, marker=\"o\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tic-tac-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
